---
title: "Predicting Next Purchase of an Instacart Consumer"
date: "4/19/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## LOAD LIBRARY AND FILES

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(recommenderlab)
library(lubridate)
aisles <- read_csv("~/Downloads/instacart-market-basket-analysis/aisles.csv")
departments <- read_csv("~/Downloads/instacart-market-basket-analysis/departments.csv")
order_prior <- read_csv("~/Downloads/instacart-market-basket-analysis/order_products__prior.csv")
order_train <- read_csv("~/Downloads/instacart-market-basket-analysis/order_products__train.csv")

orders <- read_csv("~/Downloads/instacart-market-basket-analysis/orders.csv")
products <- read_csv("~/Downloads/instacart-market-basket-analysis/products.csv")

```

***EXPLORATORY DATA ANALYSIS***

#Looking at Distribution of orders by hour of day and day of week
```{r}
#Removing NAs
orders<-na.omit(orders)
orders$order_dow<-orders$order_dow+1
orders$order_dow<-wday(orders$order_dow,label=TRUE,week_start = getOption("lubridate.week.start", 7))
orders<-mutate(orders,order_dow=as.factor(order_dow))
plot1<-orders%>%
  group_by(order_hour_of_day,order_dow)%>%
  summarise(count=n())%>%
  ggplot(mapping = aes(x =order_hour_of_day, y = count, group=order_dow)) +
  geom_line(stat = 'identity', aes(color = order_dow))+
  labs(x = 'Hour of day', y = 'No. Of Orders',color="Day of week")
print(plot1)
```
#number of days since prior order
```{r}
plot2<-orders%>%
  ggplot()+geom_bar(aes(x=as.factor(days_since_prior_order)))+
  labs(x="no. of days since prior order", y="no. of orders")
print(plot2)  
```
#Proportions of Reorder
#In prior set
```{r}
plot3<-orders_prior%>%
  group_by(reordered)%>%
  summarise(count=n())%>%
  mutate(proportion=round(count/sum(count),2))%>%
  ggplot(aes(x=as.factor(reordered),y=proportion,fill=as.factor(reordered)))+
  geom_col(width=0.5)+
  labs(x="Reordered",y="Proportion",fill="Reorder")+
  geom_text(aes(label=proportion),vjust=-0.5)
print(plot3)

#In train set
plot4<-orders_train%>%
  group_by(reordered)%>%
  summarise(count=n())%>%
  mutate(proportion=round(count/sum(count),2))%>%
  ggplot(aes(x=as.factor(reordered),y=proportion,fill=as.factor(reordered)))+
  geom_col(width=0.5)+
  labs(x="Reordered",y="Proportion",fill="Reorder")+
  geom_text(aes(label=proportion),vjust=-0.5)
print(plot4)
```
#Top 20 products that have highest probability of reorder
```{r}
plot5<-orders_prior %>%
  group_by(product_id) %>%
  summarise(prop_reorder=round(mean(reordered),4)) %>%
  arrange(desc(prop_reorder)) %>%
  left_join(products,by=c("product_id"="product_id"))%>%
  select(product_id,product_name,prop_reorder)%>%
  head(n=20)%>%
  ggplot(aes(x=reorder(product_name,prop_reorder),
                        y=prop_reorder))+
  geom_col(fill="darkred")+
  coord_flip()+labs(x="Product Name", y="Proportion of reorder")+
  geom_text(aes(label=prop_reorder),hjust=1,color="white")+
  ggtitle("TOP 20 products with highest proportion of reorder")
print(plot5)
```
#Top 10 departments by number of orders 
```{r}
order_products<-orders_prior%>%
  left_join(products)
plot6<-order_products%>%
  group_by(department_id)%>%
  summarise(count=n())%>%
  left_join(departments)%>%
  arrange(desc(count))%>%
  head(n=10)%>%
  ggplot(aes(x=reorder(department,-count),y=count))+
  geom_col(fill="darkred")+
  labs(x="Department Name", y="Number of Orders")+
  geom_text(aes(label=count),hjust=0.5,vjust=1,color="white")+
  ggtitle("TOP 10 Departments based on number of Orders")
 print(plot6) 
```
#Treemap for hierarchy between department and aisle
```{r}

tmp <- order_products %>% group_by(department_id, aisle_id) %>% summarize(n=n())
tmp <- tmp %>% left_join(departments,by="department_id")
tmp <- tmp %>% left_join(aisles,by="aisle_id")

tmp2<-order_products %>% 
  group_by(product_id) %>% 
  summarize(count=n()) %>% 
  left_join(products,by="product_id") %>% 
  ungroup() %>% 
  group_by(department_id,aisle_id) %>% 
  summarize(sumcount = sum(count)) %>% 
  left_join(tmp, by = c("department_id", "aisle_id")) %>% 
  mutate(onesize = 1)

treemap(tmp2,index=c("department","aisle"),vSize="sumcount",title="",palette="Set3",border.col="#FFFFFF")
```
#In the graph below as number of order increases probability of reorder also increases. 
#But we can see ceiling effect in the plot .
```{r}
plot7<-order_products%>%
  group_by(product_id)%>%
  summarise(prop_reorder=mean(reordered),count=n())%>%
  ggplot(aes(x=count,y=prop_reorder))+
  geom_jitter(color="darkred",alpha=0.1)+geom_smooth(color="black")+
  labs(x="Number of orders",y="proportion of reorder")+
  scale_x_continuous(limits=c(0,89000))+
  ggtitle("Number of orders VS Proportion of reorder")
print(plot7)
```
#Top 10 products added to cart first
```{r}
df1<-order_products%>%group_by(order_id)%>%
  summarise(count=n())%>%
  filter(count>3)%>%
  arrange(count)%>%
  left_join(order_products)
plot8<-df1%>%
  group_by(product_name, add_to_cart_order) %>% 
  summarize(count = n()) %>% mutate(pct=round(count/sum(count),2)) %>% 
  filter(add_to_cart_order == 1, count>10) %>% 
  arrange(desc(pct)) %>% 
  select(product_name, pct, count) %>% 
  ungroup() %>% 
  top_n(10, wt=pct)%>%
  ggplot(aes(x=reorder(product_name,pct), y=pct))+
  geom_bar(stat="identity",fill="darkred")+coord_flip()+
  labs(x="Product Name",y="Percentage")+
  geom_text(aes(label=pct),hjust=1,color="white")+
  ggtitle("Top 10 products added to cart first")
print(plot8)
```
#There are 13,84,617 products in the order_products_train file and 3,24,34,489 products in the order_products_prior file. Both files have 4 feature columns:
#The ID of the order (order_id)
#The ID of the product (product_id)
#The ordering of that product in the order (add_to_cart_order)
#Whether that product was reordered (reordered).
#we combine both files to find the unique items
```{r insta_combining_files}
order_products <- rbind(order_products_train,order_products_prior)
#unique customers

order_products %>% distinct(order_id) %>% count()

#unique products
order_products %>% distinct(product_id) %>% count()
```
#Overall, there are 33,46,083 unique orders for 49,685 unique products. 

```{r,warning=FALSE,message=FALSE,insta_ordernumbers}
# How many items were ordered the most
order_products %>% group_by(order_id)  %>% count()%>% group_by(n) %>% count() %>% head(20)%>%
  ggplot() + aes(x = reorder(n,nn),nn) + 
  geom_col(stat = "identity",fill = "darkred") +
    coord_flip() + 
  labs(title = "       Number of items orders in a Transaction ") +
 xlab("Number of items in a Transaction") +ylab("Number of transactions")
```

# most reordered items
```{r,warning=FALSE,message=FALSE,insta_most_reordered}
order_products %>% 
  group_by(product_id )%>% 
  summarise(x=sum(reordered))%>% arrange(desc(x) ) %>% 
  left_join(products) %>% 
  head(20) %>%ggplot() + aes(x = reorder(product_name,x),x) + geom_col(stat = "identity",fill = "darkred") + coord_flip() + labs(title = "       Most Frequently Reordered items     ") +xlab("Product name") +ylab("Frequency")  +
  geom_text(aes(label=x), hjust=1, color = "white")

```

```{r,warning=FALSE,message=FALSE,insta_orders}

str(orders)
head(orders,20)
```

***Generating frequent item sets and association rules***


```{r dataviz}
# get the shopping baskets
order_baskets <- order_products %>% 
  group_by(order_id) %>% count()
#ordet_baskets
order_baskets %>% group_by(n) %>% count %>%  
  head(15) %>%ggplot() + aes(reorder(n,nn),nn)+geom_col(fill = "darkred")  + coord_flip() +
  geom_text(aes(label=nn), hjust=1, color = "white")+ 
  labs(title = " Number of Items in a Basket") +
  xlab("Number of Items in a Basket") +
  ylab("Frequency") 
```

#We see that mostly peoply buy 3 to 7 items in an order.

***Frequent Itemsets***

#Now, lets compute the frequent itemsets. We decrease the support threshold to take into account the small probability of observing a frequent itemset of at least size 2.   
#With a support threshold of 0.008 (~25k baskets), we observe frequent pairs 


```{r,insta_frequent_itemsets}
support <- 0.01
itemsets <- apriori(transactions, parameter = list(target = "frequent itemsets", supp=support, maxlen=6), control = list(verbose = FALSE))

par(mar=c(5,18,2,2)+.1)
sets_order_supp <- DATAFRAME(sort(itemsets, by="support", decreasing = F))
barplot(sets_order_supp$support, names.arg=sets_order_supp$items, xlim=c(0,0.02), horiz = T, las = 2, cex.names = .8, main = "Frequent Itemsets of size = 2",col="darkred",border="darkred")
mtext(paste("support:",support), padj = .8)
```
#We observe that Bananas/Bag of Organic Bananas are most paired up items! Each of the eight pairs with highest support contains bananas. Nearly all of the items are either fruits or vegetables. There is just one frequent pair that contains milk or spinach. 
 
```{r insta_baskets}
order_baskets <- order_products %>% 
  inner_join(products, by="product_id") %>% 
  group_by(order_id) %>%
  summarise(basket = as.vector(list(product_name)))
```

```{r insta_transactions}
transactions <- as(order_baskets$basket, "transactions")
```

#We determine which items are frequent. We set the support threshold to 0.02, that means an item will be considered as frequent iff at least 2 percent of all the baskets contain it. So in our case, an item will be considered as being frequent if it is contained in more than 64,000 baskets.

```{r,insta_frequent_items}
item_frequencies <- itemFrequency(transactions, type="a")
support <- 0.01
freq_items <- sort(item_frequencies, decreasing = F)
freq_items <- freq_items[freq_items>support*length(transactions)] %>% tail(20)
tail(freq_items)
par(mar=c(5,10,2,2)); options(scipen=5)
barplot(freq_items, horiz=T, las=1, main="Frequent Items ", xlab = "Number of orders",cex.names=.8, xlim=c(0,500000),col = "darkred",border="darkred")
mtext(paste("support:",support), padj = .8)
abline(v=support*length(transactions), col="white")
#glimpse(item_frequencies)

```
***Association Rules***   

#We use a low support threshold and a high confidence to generate strong rules even for items that are less frequent.

```{r,insta_rules1}
rules1 <- apriori(transactions, parameter = list(supp = 0.00001, conf = 0.6, maxlen=6), control = list(verbose = FALSE))
summary(quality(rules1))
```
```{r, insta_plot_rules1}

plot(rules1, col=sequential_hcl(4, palette = "Reds 3"),jitter=0)

```

#We see some rules with a large lift value ,indicating a strong association between the items. Let’s see the top 5 rules by lift.



```{r,insta_rules1_lift}
inspect(sort(rules1, by="lift")[1:5])
```
#Its odd that we do not see any rules with bananas as expected . As we saw earlier that Bananas were present in top 8 frequest itemsets.
#Let’s see the top 5 rules by confidence.

```{r,insta_rules1_conf}
inspect(sort(rules1, by="confidence")[1:5])
```

#Its odd that, again,  we do not see any rules with bananas.


```{r, insta_graph_rules1}
plot(head(sort(rules1 , by="lift"),10), method="graph", control=list(type="items"))
```



#We will try some other sets of rules:
#Here Next, we increase the support and decrease confidence to get rules of some more frequent items but with less confidence.
```{r, insta_rules2}
rules2 <- apriori(transactions, parameter = list(supp = 0.001, conf = 0.4, maxlen=6), control = list(verbose = FALSE))
plot(rules2, col=sequential_hcl(4, palette = "Reds 3"),jitter=0)
```


```{r, insta_rules2_lift}
inspect(sort(rules2, by="lift")[1:5])

```

#checking by confidence
```{r, insta_rules2_conf}
inspect(sort(rules2, by="confidence")[1:5])
```

```{r, insta_graph_rules2}
plot(head(sort(rules2 , by="lift"),10), method="graph", control=list(type="items"))
```

#Finally, lets further increase support and decrease confidence
```{r , insta_rules3}
rules3 <- apriori(transactions, parameter = list(supp = 0.01, conf = 0.1, maxlen=6), control = list(verbose = FALSE)) 
plot(rules3, col=sequential_hcl(4, palette = "Reds 3"),jitter=0)
```
```{r , insta_plot_rules3_lift}
inspect(sort(rules3, by="lift")[1:5])
```
```{r, insta_plot_rules3_conf}
inspect(sort(rules3, by="confidence")[1:5])

```
```{r , insta_graph_rules3}
plot(head(sort(rules3 , by="lift"),10), method="graph", control=list(type="items"))
```

***Recommender system***

## TIDY DATA FOR TRAIN

```{r}

# pick users with most orders

df_prior <- order_prior %>% 
  left_join(products) %>% 
  select(product_id,order_id,product_name, department_id) 
df_prior <- df_prior %>% 
  left_join(orders) %>% 
  select(order_id,product_id,product_name,department_id,user_id)
df_prior <- df_prior %>% 
  left_join(departments) %>%
  select(order_id,product_id,product_name,department_id,department,user_id)

frequent_users <- df_prior %>%
  count(user_id, sort = TRUE) %>%
  mutate(user_id = reorder(user_id,n)) %>%
  top_n(200) %>% select(user_id)

df_prior_try <- df_prior %>%
  filter(user_id %in% frequent_users$user_id)

df_prior_try <- df_prior_try %>% 
  group_by(product_id) %>% 
  mutate(times_ordered = n()) %>% 
  filter(times_ordered > 50) %>%
  ungroup(product_id) %>%
  select(-times_ordered)

```

# TEST DATA FRAME

```{r}
df <- order_train %>% 
  left_join(products) %>% 
  select(product_id,order_id,product_name, department_id) 
df <- df %>% 
  left_join(orders) %>% 
  select(order_id,product_id,product_name,department_id,user_id)
df <- df %>% 
  left_join(departments) %>%
  select(order_id,product_id,product_name,department_id,department,user_id)
df_try <- df %>% 
  filter(user_id %in% frequent_users$user_id)

```

# TRAINING DATA MATRIX

```{r}

dept_mat <- df_prior_try %>% 
  group_by(user_id, department) %>% 
  distinct(department) %>%
  select(department, user_id) %>% 
  ungroup(user_id, department) %>%
  mutate(value=1) %>%
  spread(department, value, fill=0) %>%
  select(-user_id)

prod_mat <- df_prior_try %>% 
  group_by(user_id, product_name) %>% 
  distinct(product_name) %>%
  select(product_name, user_id) %>% 
  ungroup(user_id, product_name) %>%
  mutate(value=1) %>%
  spread(product_name, value, fill=0) %>%
  select(-user_id)

heatmap(as.matrix(dept_mat[1:50,1:19]), Colv=NA, Rowv=NA, scale='none',
         ylab = "User Ids", main = "Departments ordered from")
heatmap(as.matrix(prod_mat[1:50,1:50]), Colv=NA, Rowv=NA, scale='none',
         ylab = "User Ids", main = "Products ordered")
```

# SCHEME BUILDING

```{r}
dept_mat <- dept_mat %>% as.matrix() %>% as("binaryRatingMatrix")
image(dept_mat[1:50,])
scheme <- dept_mat %>% 
  evaluationScheme(method = "cross",
                   k      = 5, 
                   train  = 0.8,
                   given  = -1)
scheme
```

```{r}
prod_mat <- prod_mat %>% as.matrix() %>% as("binaryRatingMatrix")
image(prod_mat[1:50,])
scheme_by_prod <- prod_mat %>% 
  evaluationScheme(method = "cross",
                   k      = 5, 
                   train  = 0.8,
                   given  = -1)
scheme_by_prod
```

# Algorithms Comparison

```{r}
algorithms <- list(
  "association rules" = list(name  = "AR",
                             param = list(supp = 0.5, conf = 0.03)),
  "random items"      = list(name  = "RANDOM",  param = NULL),
  "popular items"     = list(name  = "POPULAR", 
                             param = NULL),
  "item-based CF"     = list(name  = "IBCF", 
                             param = list(method = "Cosine",k = 5)),
  "user-based CF"     = list(name  = "UBCF", 
                        param = list(method = "Cosine", nn = 500))
                   )
dept_results <- recommenderlab::evaluate(scheme, 
                                    algorithms, 
                                    type  = "topNList", 
                                    n     = c(1,3,5,10)
                                    )
avg(dept_results)
plot(dept_results)
plot(dept_results, "prec/rec", legend="topright")

```


```{r}
prod_results <- recommenderlab::evaluate(scheme_by_prod, 
                                    algorithms, 
                                    type  = "topNList", 
                                    n     = c(1, 3, 5, 10)
                                    )
avg(prod_results)
plot(prod_results)
plot(prod_results, "prec/rec", legend="topright")
```


```{r}
avg_conf_matr <- function(results) {
  tmp <- results %>%
    getConfusionMatrix()  %>%  
    as.list() 
    as.data.frame(Reduce("+",tmp) / length(tmp)) %>% 
    mutate(n = c(1, 3, 5, 10)) %>%
    select('n', 'precision', 'recall', 'TPR', 'FPR') 
}

results_tbl <- prod_results %>%
  map(avg_conf_matr) %>% 
  enframe() %>%
  unnest()

results_tbl %>%
  ggplot(aes(FPR, TPR, 
             colour = fct_reorder2(as.factor(name), 
                      FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "ROC curves on product rating matrix", colour = "Model") +
  theme_grey(base_size = 14)


results_dept_tbl <- dept_results %>%
  map(avg_conf_matr) %>% 
  enframe() %>%
  unnest()

results_dept_tbl %>%
  ggplot(aes(FPR, TPR, 
             colour = fct_reorder2(as.factor(name), 
                      FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "ROC curves on department rating matrix", colour = "Model") +
  theme_grey(base_size = 14)
```

# Item Based Collaborative Filtering on Departments

```{r}
dept_ids_trained_on <- unique(df_prior_try$department_id)
new_dept_cols <- setdiff(dept_ids_trained_on, df_try$department_id)

dept_test_order <- c("produce",
                     "beverages")

mat_dept_test<- df_try %>% 
  filter(department_id %in% dept_ids_trained_on) %>%
  select(department) %>%
  unique() %>%
  mutate(value=as.numeric(department %in% dept_test_order))%>%
  spread(key=department,value=value) 

for (col in new_dept_cols){
  mat_dept_test$new_col <- rep(0, nrow(mat_dept_test))
  names(mat_dept_test)[names(mat_dept_test) == "new_col"] <- col
}
  
mat_dept_test <- mat_dept_test %>%
  as.matrix() %>%
  as("binaryRatingMatrix")

recomm_UBCF_dept <- Recommender(getData(scheme, 'train'),
                       method = "UBCF")
recomm_UBCF_dept

pred_UBCF_dept <- predict(recomm_UBCF_dept,
                newdata = mat_dept_test,
                n= 5)
dept_IBCF_prediction <- as(pred_UBCF_dept,'list')
dept_IBCF_prediction

# OUTPUT--------------------------------------------------
#Recommender of type ‘IBCF’ for ‘binaryRatingMatrix’ 
#learned using 298 users.
#$`1`
#[1] "dairy eggs" "frozen"     "pantry"     "beverages" 

#Recommendations as ‘topNList’ with n = 4 for 1 users.

##VALIDATION of the above prediction------------------------
test_order_ids <- df_try %>%
  group_by(order_id) %>% 
  filter(department %in% dept_test_order) %>% 
  select(order_id)

test_orders <- df_try %>% 
  filter(order_id %in% test_order_ids$order_id)

test_orders %>% 
  group_by(department) %>% 
  count(sort = TRUE) %>% 
  ungroup() %>%
  mutate(department = reorder(department, n)) %>%
  top_n(10) %>%
  ggplot() + geom_col(aes(department,n), fill = "darkred") + coord_flip() +
  labs(title = "Most frequent departments ordered from along with produce and beverages")


```

```{r}
product_ids_trained_on <- unique(df_prior_try$product_name)
new_cols <- setdiff(product_ids_trained_on, df_try$product_name)

prod_test_order <- c("Ancient Grain Blueberry Hemp Granola",
                     "Tuna Salad",
                     "Organic Raspberries",
                     "Ground Turkey Breast",
                     "Organic Sour Cream")

prod_mat_test <- df_try %>% 
  filter(product_name %in% product_ids_trained_on) %>%
  select(product_name) %>%
  unique() %>%
  mutate(value=as.numeric(product_name %in% prod_test_order))%>%
  spread(key=product_name,value=value)

for (col in new_cols){
  prod_mat_test$new_col <- rep(0, nrow(prod_mat_test))
  names(prod_mat_test)[names(prod_mat_test) == "new_col"] <- col
}

prod_mat_test <- prod_mat_test %>%
  as.matrix()%>%
  as("binaryRatingMatrix")


recomm_UBCF <- Recommender(data = getData(scheme_by_prod, 'train'),
                       method = "UBCF")
recomm_UBCF

pred_UBCF <- predict(object = recomm_UBCF,
                     newdata = prod_mat_test,
                     n= 10)
pred_UBCF_product <- as(pred_UBCF,'list')

pred_UBCF_product

##----------------VALIDATION of the above prediction------------------------
prod_test_order_ids <- df_try %>%
  group_by(order_id) %>% 
  filter(product_name %in% prod_test_order) %>% 
  select(order_id)

prod_test_orders <- df_try %>% 
  filter(order_id %in% prod_test_order_ids$order_id)

prod_test_orders %>% 
  group_by(product_name) %>% 
  mutate(count = n()) %>% 
  ungroup() %>%
  mutate(product_name = reorder(product_name, count)) %>%
  top_n(50) %>%
  ggplot() + geom_col(aes(product_name,count, fill = department), fill = "darkred") + coord_flip() + 
  labs(x = "product name", title = "Most frequent products ordered along with the test products")

```

## Similarity on Department MATRIX

```{r}
#Users vs Departments
user_similarity_by_dept <- as.matrix(similarity(dept_mat, 
                                                method = "cosine",
                                                which = "users"))

#1
heatmap(user_similarity_by_dept[1:20,1:20],
        main = "Similarity among Users on the basis of Department",
        xlab = "User Ids", 
        ylab = "User Ids",
        keep.dendro = FALSE,
        verbose = getOption("verbose"),
        Colv=NA, Rowv=NA, scale='none')

#Items vs Departments

items_sim_by_dept <- as.matrix(similarity(dept_mat, method = "cosine", which = "items"))
heatmap(items_sim_by_dept[1:19,1:19], 
        main = "Similarity among Departments",
        keep.dendro = FALSE,
        verbose = getOption("verbose"),
        Colv=NA, Rowv=NA, scale='none')

library(gplots)
heatmap.2(items_sim_by_dept[1:19,1:19],dendrogram='none', Rowv=TRUE, Colv=TRUE,trace='none')
```

## Similarity on PRODUCT MATRIX

```{r}
user_similarity_by_product <- as.matrix(similarity(prod_mat, 
                                                method = "cosine",
                                                which = "users"))

heatmap(user_similarity_by_product[1:20,1:20],
        main = "Similarity among Users based on Products ordered",
        keep.dendro = FALSE,
        verbose = getOption("verbose"),Colv=NA, Rowv=NA, scale='none')
#image(user_similarity_by_product[1:10,1:10], main = "User Similarity Product")

items_sim_by_prod <- as.matrix(similarity(prod_mat, 
                                          method = "cosine", 
                                          which = "items"))
randIndices <- sample(1:1600, 20, replace=TRUE)

heatmap(items_sim_by_prod[randIndices,randIndices], 
        main = "Similarity among Products",
        keep.dendro = FALSE,
        verbose = getOption("verbose"),Colv=NA, Rowv=NA, scale='none')
#image(items_sim_by_prod[1:20,1:20], main = "Item Similarity Product")

```
